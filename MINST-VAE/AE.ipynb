{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# For dataset preparation\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "# For building neural networks\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# For training\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    # Where the data are stored. If this is a relative path, \n",
    "    # the path is assumed to start from the current working directory. \n",
    "    # Therefore you can find a data folder coming together with this notebook.\n",
    "    root=\"./data\",  \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "training_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=len(test_data), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the shape of each image in the training dataset:\n",
    "we have one \"channel\" which is used probably used for CNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderMLP(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(784, 512)\n",
    "        self.linear2 = nn.Linear(512, latent_dim)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        # Since we are not defining a CNN, \n",
    "        # we just ignore the channel dimension \n",
    "        # and collapse everything into one dimension.\n",
    "        xb = torch.flatten(xb, start_dim=1)\n",
    "        xb = self.linear1(xb)\n",
    "        xb = F.relu(xb)\n",
    "        xb = self.linear2(xb)\n",
    "        return xb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the decoder, in our simple demo,\n",
    "is exactly the opposite to that of the encoder.\n",
    "But the activation function is different:\n",
    "we need sigmoid to make sure the output is properly normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderMLP(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(latent_dim, 512)\n",
    "        self.linear2 = nn.Linear(512, 784)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = self.linear1(xb)\n",
    "        xb = F.sigmoid(xb)\n",
    "        xb = self.linear2(xb)\n",
    "        # Make sure the shape of the output tensor looks the same as \n",
    "        # that of the input data.\n",
    "        # Since xb in the last step has the batch dimension as the first dimension. \n",
    "        xb = torch.reshape(xb, (-1, 1, 28, 28)) \n",
    "        return xb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still need to glue the encoder and the decoder together into the shape of an hourglass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderMLP(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderMLP(latent_dim)\n",
    "        self.decoder = DecoderMLP(latent_dim)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        z = self.encoder(xb)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the model here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2 \n",
    "ae = AutoencoderMLP(latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See whether CUDA is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ae = ae.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, lr, epoches):\n",
    "    optimizer = SGD(model.parameters(), lr=lr)\n",
    "    for epoch in range(epoches):\n",
    "        model.train()\n",
    "        for X, Y in dataloader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            \n",
    "            Xhat = model(X) \n",
    "            loss = ((X - Xhat)**2).sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        model.eval() \n",
    "        with torch.no_grad():\n",
    "            for X, Y in test_dataloader:\n",
    "                X = X.to(device)\n",
    "                Y = Y.to(device)\n",
    "                \n",
    "                Xhat = model(X) \n",
    "                loss = ((X - Xhat)**2).mean().item()\n",
    "\n",
    "                print(f\"epoch {epoch:>3d}   test loss avg: {loss:>5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0   test loss avg: 0.067729\n",
      "epoch   1   test loss avg: 0.067714\n",
      "epoch   2   test loss avg: 0.067673\n",
      "epoch   3   test loss avg: 0.067584\n",
      "epoch   4   test loss avg: 0.067661\n"
     ]
    }
   ],
   "source": [
    "train(ae, training_dataloader, lr=0.002, epoches=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking if the autoencoder works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = test_data[10]\n",
    "x = x.to(device)\n",
    "with torch.no_grad():\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(x.to(\"cpu\")[0, :, :], cmap=\"gray\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(ae(x).to(\"cpu\")[0, 0, :, :], cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
